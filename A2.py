import sounddevice as sd
import numpy as np
import wave
import base64
import requests
import pygame
import time
import os
import webrtcvad
import threading
import keyboard
from aip import AipSpeech
from config import BAIDU_API_KEY, BAIDU_SECRET_KEY, BAIDU_ASR_URL
import tkinter as tk
from tkinter import ttk, messagebox, simpledialog, scrolledtext

ASR_CONFIG = {
    "api_key": BAIDU_API_KEY,
    "secret_key": BAIDU_SECRET_KEY,
    "url": BAIDU_ASR_URL,
    "dev_pid": 1537
}

TTS_CONFIG = {
    "app_id": "119812145",
    "api_key": "p9vdGZYrapwbhRNLVtBos2yi",
    "secret_key": "CQxpf1UWJlZEwKbUCfpgKryfbhtGU4hl",
    "default_out": "response.mp3",
    "per": 0,
    "vol": 5,
    "spd": 5,
    "pit": 5,
    "daily_char_limit": 999000
}

tts_client = AipSpeech(TTS_CONFIG["app_id"], TTS_CONFIG["api_key"], TTS_CONFIG["secret_key"])

CHAR_COUNT_FILE = "tts_char_count.txt"
VAD_CONFIG = {
    "mode": 2,
    "sample_rate": 16000,
    "frame_duration_ms": 30,
    "silence_threshold": 100,
    "loud_sound_frames": 5,
    "min_loud_frames": 1,
    "max_loud_frames": 30
}
VAD_FRAME_SIZE = int(VAD_CONFIG["sample_rate"] * VAD_CONFIG["frame_duration_ms"] / 1000)

conversation_history = []
waiting_for_wakeup = True
DEFAULT_MIC = None
input_mode = "voice"
mode_lock = threading.Lock()
ai_background = ""
show_control_panel = False
wake_word = "ä½ å¥½"

def setup_mode_switch_listener():
    def on_enter_press():
        global input_mode
        with mode_lock:
            if input_mode != "text":
                input_mode = "text"
                print("\nâŒ¨ï¸ å·²åˆ‡æ¢åˆ°æ–‡å­—è¾“å…¥æ¨¡å¼ï¼ˆæŒ‰Tabé”®è¿”å›è¯­éŸ³è¾“å…¥ï¼‰")

    def on_tab_press():
        global input_mode
        with mode_lock:
            if input_mode != "voice":
                input_mode = "voice"
                print("\nğŸ¤ å·²åˆ‡æ¢åˆ°è¯­éŸ³è¾“å…¥æ¨¡å¼ï¼ˆæŒ‰Enteré”®åˆ‡æ¢åˆ°æ–‡å­—è¾“å…¥ï¼‰")

    def on_alt_press():
        global show_control_panel
        if not waiting_for_wakeup:
            show_control_panel = True
            print("\nâŒ¨ï¸ æ£€æµ‹åˆ°Alté”®ï¼Œå·²è®¾ç½®show_control_panel=True")

    keyboard.add_hotkey('enter', on_enter_press)
    keyboard.add_hotkey('tab', on_tab_press)
    keyboard.add_hotkey('alt', on_alt_press)
    print("âŒ¨ï¸ å¿«æ·é”®ï¼šæŒ‰Enteråˆ‡æ¢æ–‡å­—è¾“å…¥ï¼ŒTabåˆ‡æ¢è¯­éŸ³è¾“å…¥ï¼ŒAltæ‰“å¼€æ§åˆ¶é¢æ¿")

def get_text_input(prompt: str = "è¯·è¾“å…¥æ–‡å­—: ") -> str:
    root = tk.Tk()
    root.withdraw()
    user_input = simpledialog.askstring("æ–‡å­—è¾“å…¥", prompt)
    root.destroy()
    return user_input.strip() if user_input else ""

def create_control_panel():
    global ai_background, conversation_history, waiting_for_wakeup, wake_word

    root = tk.Tk()
    root.title("è¯­éŸ³åŠ©æ‰‹å‚æ•°æ§åˆ¶é¢æ¿")
    root.geometry("600x600")
    root.resizable(False, False)

    main_frame = tk.Frame(root)
    main_frame.pack(fill=tk.BOTH, expand=1)
    canvas = tk.Canvas(main_frame)
    scrollbar = ttk.Scrollbar(main_frame, orient=tk.VERTICAL, command=canvas.yview)
    scrollable_frame = tk.Frame(canvas)

    scrollable_frame.bind("<Configure>", lambda e: canvas.configure(scrollregion=canvas.bbox("all")))

    canvas.create_window((0, 0), window=scrollable_frame, anchor="nw")
    canvas.configure(yscrollcommand=scrollbar.set)
    canvas.pack(side=tk.LEFT, fill=tk.BOTH, expand=1)
    scrollbar.pack(side=tk.RIGHT, fill=tk.Y)

    current_params = {
        "vad_mode": VAD_CONFIG["mode"],
        "vad_silence": VAD_CONFIG["silence_threshold"],
        "vad_loud": VAD_CONFIG["loud_sound_frames"],
        "tts_vol": TTS_CONFIG["vol"],
        "tts_spd": TTS_CONFIG["spd"],
        "tts_pit": TTS_CONFIG["pit"],
        "tts_per": TTS_CONFIG["per"],
        "ai_background": ai_background,
        "wake_word": wake_word
    }

    mbti_descriptions = {
        "INTJ": "ä½ æ˜¯ä¸€ä¸ªæˆ˜ç•¥æ€§ã€é€»è¾‘æ€§å¼ºçš„äººï¼Œæ“…é•¿é•¿æœŸè§„åˆ’ã€‚",
        "INTP": "ä½ æ˜¯ä¸€ä¸ªå–œæ¬¢åˆ†æå’Œæ¢ç´¢æ¦‚å¿µçš„é€»è¾‘å‹æ€è€ƒè€…ã€‚",
        "ENTJ": "ä½ æ˜¯ä¸€ä¸ªæœæ–­ã€æ“…é•¿é¢†å¯¼å’Œç»„ç»‡çš„å¤–å‘å‹äººç‰©ã€‚",
        "ENTP": "ä½ æ˜¯ä¸€ä¸ªæœºæ™ºã€å–œæ¬¢è¾©è®ºå’Œæ–°æƒ³æ³•çš„æ¢ç´¢è€…ã€‚",
        "INFJ": "ä½ æ˜¯ä¸€ä¸ªç†æƒ³ä¸»ä¹‰è€…ï¼Œå…³å¿ƒä»–äººå¹¶å¯Œæœ‰æ´å¯ŸåŠ›ã€‚",
        "INFP": "ä½ æ˜¯ä¸€ä¸ªå†…çœã€å¯Œæœ‰åŒç†å¿ƒå’Œæƒ³è±¡åŠ›çš„äººã€‚",
        "ENFJ": "ä½ æ˜¯ä¸€ä¸ªå–„äºæ¿€åŠ±ä»–äººçš„é¢†å¯¼è€…å’Œæ²Ÿé€šè€…ã€‚",
        "ENFP": "ä½ æ˜¯ä¸€ä¸ªå¤–å‘ã€å¯Œæœ‰åˆ›é€ åŠ›å’ŒåŒç†å¿ƒçš„äººï¼Œå–œæ¬¢æ¢ç´¢æ–°æƒ³æ³•ã€‚",
        "ISTJ": "ä½ æ˜¯ä¸€ä¸ªå¯é ã€è´Ÿè´£ã€æ³¨é‡ç»†èŠ‚çš„ç°å®ä¸»ä¹‰è€…ã€‚",
        "ISFJ": "ä½ æ˜¯ä¸€ä¸ªä¹äºåŠ©äººã€é‡è§†å’Œè°çš„å®ˆæŠ¤è€…ã€‚",
        "ESTJ": "ä½ æ˜¯ä¸€ä¸ªåŠ¡å®ã€å–„äºç®¡ç†å’Œç»„ç»‡çš„é¢†å¯¼è€…ã€‚",
        "ESFJ": "ä½ æ˜¯ä¸€ä¸ªå–„äºåˆä½œã€å…³å¿ƒä»–äººçš„ç¤¾äº¤å‹äººç‰©ã€‚",
        "ISTP": "ä½ æ˜¯ä¸€ä¸ªåŠ¨æ‰‹èƒ½åŠ›å¼ºã€å–œæ¬¢æ¢ç´¢å®é™…è§£å†³æ–¹æ¡ˆçš„äººã€‚",
        "ISFP": "ä½ æ˜¯ä¸€ä¸ªæ¸©æŸ”ã€å¯Œæœ‰åˆ›é€ åŠ›å’Œè‰ºæœ¯æ„Ÿçš„äººã€‚",
        "ESTP": "ä½ æ˜¯ä¸€ä¸ªè¡ŒåŠ¨å¯¼å‘ã€å–œæ¬¢å†’é™©å’Œå°è¯•æ–°äº‹ç‰©çš„äººã€‚",
        "ESFP": "ä½ æ˜¯ä¸€ä¸ªå¤–å‘ã€å–œæ¬¢è¡¨æ¼”å’Œäº«å—ç”Ÿæ´»çš„ä¹è§‚è€…ã€‚"
    }

    def save_params():
        nonlocal root
        global ai_background, wake_word, waiting_for_wakeup, conversation_history

        VAD_CONFIG["mode"] = int(vad_mode_slider.get())
        VAD_CONFIG["silence_threshold"] = int(vad_silence_slider.get())
        VAD_CONFIG["loud_sound_frames"] = int(vad_loud_slider.get())
        TTS_CONFIG["vol"] = int(tts_vol_slider.get())
        TTS_CONFIG["spd"] = int(tts_spd_slider.get())
        TTS_CONFIG["pit"] = int(tts_pit_slider.get())
        TTS_CONFIG["per"] = tts_per_var.get()

        new_background = ai_background_text.get("1.0", tk.END).strip()
        new_wake_word = wake_word_entry.get().strip()
        selected_mbti = mbti_var.get()

        background_changed = new_background != current_params["ai_background"]
        wake_word_changed = new_wake_word != current_params["wake_word"] and new_wake_word

        if wake_word_changed:
            wake_word = new_wake_word

        if selected_mbti:
            ai_background = mbti_descriptions[selected_mbti] + "\n" + new_background
            conversation_history.clear()
            waiting_for_wakeup = True
        elif background_changed:
            ai_background = new_background
            conversation_history.clear()
            if not waiting_for_wakeup:
                waiting_for_wakeup = True

        messages = []
        if selected_mbti:
            messages.append(f"äººæ ¼å·²è®¾å®šä¸ºï¼š{selected_mbti}")
        if background_changed:
            messages.append("AIèƒŒæ™¯è®¾å®šå·²æ›´æ–°ï¼Œå¯¹è¯å·²é‡ç½®")
        if wake_word_changed:
            messages.append(f"å”¤é†’è¯å·²æ›´æ–°ä¸ºï¼š{new_wake_word}")
        if not messages:
            messages.append("å‚æ•°å·²ä¿å­˜")

        messagebox.showinfo("æˆåŠŸ", "\n".join(messages))
        root.destroy()

    def cancel_params():
        root.destroy()

    wake_word_frame = ttk.LabelFrame(scrollable_frame, text="å”¤é†’è¯è®¾ç½®", padding=(10, 5))
    wake_word_frame.pack(fill=tk.X, padx=20, pady=(15, 5))
    ttk.Label(wake_word_frame, text="å½“å‰å”¤é†’è¯ï¼š").grid(row=0, column=0, sticky=tk.W, pady=8, padx=(0, 10))
    wake_word_entry = ttk.Entry(wake_word_frame, width=30)
    wake_word_entry.grid(row=0, column=1, sticky=tk.W, pady=8)
    wake_word_entry.insert(0, current_params["wake_word"])

    ai_frame = ttk.LabelFrame(scrollable_frame, text="AIèƒŒæ™¯è®¾å®š", padding=(10, 5))
    ai_frame.pack(fill=tk.X, padx=20, pady=(10, 5))
    ai_background_text = scrolledtext.ScrolledText(ai_frame, height=5, wrap=tk.WORD)
    ai_background_text.pack(fill=tk.X, pady=(0, 10))
    ai_background_text.insert(tk.END, current_params["ai_background"])

    mbti_frame = ttk.LabelFrame(scrollable_frame, text="MBTIäººæ ¼è®¾å®š", padding=(10, 5))
    mbti_frame.pack(fill=tk.X, padx=20, pady=(10, 5))
    ttk.Label(mbti_frame, text="è¯·é€‰æ‹©äººæ ¼ç±»å‹ï¼š").grid(row=0, column=0, sticky=tk.W, pady=8)
    mbti_var = tk.StringVar(value="")
    mbti_menu = ttk.OptionMenu(mbti_frame, mbti_var, "", *mbti_descriptions.keys())
    mbti_menu.grid(row=0, column=1, padx=10, sticky=tk.EW)

    vad_frame = ttk.LabelFrame(scrollable_frame, text="VADè¯­éŸ³æ£€æµ‹é…ç½®", padding=(10, 5))
    vad_frame.pack(fill=tk.X, padx=20, pady=(10, 5))
    ttk.Label(vad_frame, text="VADçµæ•åº¦ï¼ˆ0=ä½ï¼Œ3=é«˜ï¼‰ï¼š").grid(row=0, column=0, sticky=tk.W, pady=8)
    vad_mode_slider = ttk.Scale(vad_frame, from_=0, to=3, orient=tk.HORIZONTAL, value=current_params["vad_mode"])
    vad_mode_slider.grid(row=0, column=1, padx=10, sticky=tk.EW)

    ttk.Label(vad_frame, text="å½•éŸ³é™éŸ³åœæ­¢æ—¶é—´ï¼ˆå¸§ï¼Œ1å¸§=30msï¼‰ï¼š").grid(row=1, column=0, sticky=tk.W, pady=8)
    vad_silence_slider = ttk.Scale(vad_frame, from_=50, to=200, orient=tk.HORIZONTAL, value=current_params["vad_silence"])
    vad_silence_slider.grid(row=1, column=1, padx=10, sticky=tk.EW)

    ttk.Label(vad_frame, text="ä¸­æ–­æ’­æ”¾çš„å£°éŸ³æ—¶é•¿ï¼ˆå¸§ï¼Œ1å¸§=30msï¼‰ï¼š").grid(row=2, column=0, sticky=tk.W, pady=8)
    vad_loud_slider = ttk.Scale(vad_frame, from_=VAD_CONFIG["min_loud_frames"], to=VAD_CONFIG["max_loud_frames"], orient=tk.HORIZONTAL, value=current_params["vad_loud"])
    vad_loud_slider.grid(row=2, column=1, padx=10, sticky=tk.EW)

    tts_frame = ttk.LabelFrame(scrollable_frame, text="TTSè¯­éŸ³åˆæˆé…ç½®", padding=(10, 5))
    tts_frame.pack(fill=tk.X, padx=20, pady=(10, 5))
    ttk.Label(tts_frame, text="éŸ³é‡ï¼ˆ0-15ï¼‰ï¼š").grid(row=0, column=0, sticky=tk.W, pady=8)
    tts_vol_slider = ttk.Scale(tts_frame, from_=0, to=15, orient=tk.HORIZONTAL, value=current_params["tts_vol"])
    tts_vol_slider.grid(row=0, column=1, padx=10, sticky=tk.EW)

    ttk.Label(tts_frame, text="è¯­é€Ÿï¼ˆ0-9ï¼‰ï¼š").grid(row=1, column=0, sticky=tk.W, pady=8)
    tts_spd_slider = ttk.Scale(tts_frame, from_=0, to=9, orient=tk.HORIZONTAL, value=current_params["tts_spd"])
    tts_spd_slider.grid(row=1, column=1, padx=10, sticky=tk.EW)

    ttk.Label(tts_frame, text="è¯­è°ƒï¼ˆ0-9ï¼‰ï¼š").grid(row=2, column=0, sticky=tk.W, pady=8)
    tts_pit_slider = ttk.Scale(tts_frame, from_=0, to=9, orient=tk.HORIZONTAL, value=current_params["tts_pit"])
    tts_pit_slider.grid(row=2, column=1, padx=10, sticky=tk.EW)

    tts_per_options = {0: "åº¦å°é¹¿", 1: "åº¦åšæ–‡", 3: "åº¦é€é¥", 4: "åº¦ä¸«ä¸«", 5: "åº¦å°å¨‡"}
    ttk.Label(tts_frame, text="å‘éŸ³äººï¼š").grid(row=3, column=0, sticky=tk.W, pady=8)
    tts_per_var = tk.IntVar(value=current_params["tts_per"])
    tts_per_menu = ttk.OptionMenu(tts_frame, tts_per_var, current_params["tts_per"], *tts_per_options.keys())
    tts_per_menu.grid(row=3, column=1, padx=10, sticky=tk.EW)

    btn_frame = ttk.Frame(scrollable_frame, padding=(10, 5))
    btn_frame.pack(fill=tk.X, padx=20, pady=(15, 20))
    save_btn = ttk.Button(btn_frame, text="ä¿å­˜å‚æ•°", command=save_params)
    save_btn.pack(side=tk.LEFT, padx=20, fill=tk.X, expand=True)
    cancel_btn = ttk.Button(btn_frame, text="å–æ¶ˆï¼ˆä¸ä¿å­˜ï¼‰", command=cancel_params)
    cancel_btn.pack(side=tk.RIGHT, padx=20, fill=tk.X, expand=True)

    root.mainloop()


# --------------------------- éº¦å…‹é£è®¾å¤‡è·å–é€»è¾‘ ---------------------------
def get_default_microphone() -> int | None:
    """å¥å£®è·å–éº¦å…‹é£è®¾å¤‡ï¼Œæ”¯æŒè‡ªåŠ¨é€‰æ‹©ä¸å…¼å®¹æ¨¡å¼"""
    try:
        print("ğŸ” æ­£åœ¨æ£€æµ‹éº¦å…‹é£è®¾å¤‡...")
        all_devices = sd.query_devices()  # è·å–æ‰€æœ‰è¾“å…¥/è¾“å‡ºè®¾å¤‡
        input_devices = [dev for dev in all_devices if dev['max_input_channels'] > 0]

        if input_devices:
            print("\nğŸ“‹ æ£€æµ‹åˆ°ä»¥ä¸‹éº¦å…‹é£è®¾å¤‡ï¼š")
            for idx, dev in enumerate(input_devices):
                print(
                    f"   {idx + 1}. è®¾å¤‡åï¼š{dev['name']} | è¾“å…¥å£°é“ï¼š{dev['max_input_channels']} | è®¾å¤‡IDï¼š{dev['index']}")

            # è‡ªåŠ¨é€‰æ‹©ç¬¬ä¸€ä¸ªå¯ç”¨éº¦å…‹é£
            default_mic_id = input_devices[0]['index']
            print(f"\nğŸ¤ è‡ªåŠ¨é€‰æ‹©ç¬¬ä¸€ä¸ªéº¦å…‹é£ï¼š{input_devices[0]['name']}ï¼ˆè®¾å¤‡IDï¼š{default_mic_id}ï¼‰")
            return default_mic_id
        else:
            print("âš ï¸  æœªæŸ¥è¯¢åˆ°æ˜ç¡®çš„è¾“å…¥è®¾å¤‡ï¼Œå°è¯•ä½¿ç”¨ç³»ç»Ÿé»˜è®¤æ¨¡å¼")
            default_input = sd.default.device[0]  # è·å–ç³»ç»Ÿé»˜è®¤è¾“å…¥è®¾å¤‡ID
            default_dev_info = sd.query_devices(default_input)
            if default_dev_info['max_input_channels'] > 0:
                print(f"ğŸ¤ ä½¿ç”¨ç³»ç»Ÿé»˜è®¤éº¦å…‹é£ï¼ˆè®¾å¤‡IDï¼š{default_input}ï¼Œåç§°ï¼š{default_dev_info['name']}ï¼‰")
                return default_input
            else:
                print("âš ï¸  ç³»ç»Ÿé»˜è®¤è®¾å¤‡ééº¦å…‹é£ï¼Œå°†ä½¿ç”¨è‡ªåŠ¨é€‚é…æ¨¡å¼")
                return None  # ä¸æŒ‡å®šè®¾å¤‡IDï¼Œè®©sounddeviceè‡ªåŠ¨å¤„ç†
    except Exception as e:
        print(f"\nâŒ è®¾å¤‡æŸ¥è¯¢å‡ºé”™ï¼š{str(e)}")
        print("ğŸ’¡ å·²åˆ‡æ¢åˆ°å…¼å®¹æ¨¡å¼ï¼Œå°è¯•è‡ªåŠ¨é€‚é…éº¦å…‹é£")
        return None


# åˆå§‹åŒ–éº¦å…‹é£
DEFAULT_MIC = get_default_microphone()


# --------------------------- 2. é…é¢ç®¡ç†å·¥å…· ---------------------------
def get_daily_char_usage() -> int:
    """è·å–å½“æ—¥TTSå­—ç¬¦ä½¿ç”¨é‡"""
    if not os.path.exists(CHAR_COUNT_FILE):
        return 0
    today = time.strftime("%Y-%m-%d")
    with open(CHAR_COUNT_FILE, "r") as f:
        lines = f.readlines()
        if len(lines) >= 2 and lines[0].strip() == today:
            return int(lines[1].strip())
    return 0


def update_char_usage(added_chars: int) -> None:
    """æ›´æ–°å½“æ—¥TTSå­—ç¬¦ä½¿ç”¨é‡"""
    today = time.strftime("%Y-%m-%d")
    current = get_daily_char_usage()
    new_total = current + added_chars
    with open(CHAR_COUNT_FILE, "w") as f:
        f.write(f"{today}\n{new_total}\n")
    # æ˜¾ç¤ºæ›´æ–°åçš„é…é¢ä½¿ç”¨æƒ…å†µï¼ˆå·²æ”¹ä¸º999000å­—ä¸Šé™ï¼‰
    print(f"ğŸ“Š TTSå­—ç¬¦ä½¿ç”¨ï¼šä»Šæ—¥å·²ç”¨ {new_total}/{TTS_CONFIG['daily_char_limit']}")


def check_quota(text: str) -> bool:
    """æ£€æŸ¥TTSå­—ç¬¦é…é¢æ˜¯å¦å……è¶³ï¼ˆä¸Šé™å·²æ”¹ä¸º999000å­—ï¼‰"""
    text_len = len(text)
    used = get_daily_char_usage()
    if used + text_len > TTS_CONFIG["daily_char_limit"]:
        print(f"âŒ é…é¢ä¸è¶³ï¼ä»Šæ—¥å·²ç”¨{used}å­—ç¬¦ï¼Œè¿˜éœ€{text_len}å­—ç¬¦ï¼ˆä¸Šé™{TTS_CONFIG['daily_char_limit']}ï¼‰")
        return False
    return True


# --------------------------- 3. åŸºç¡€å·¥å…·å‡½æ•° ---------------------------
def get_baidu_token() -> str:
    """è·å–ç™¾åº¦APIè®¿é—®Token"""
    url = (
        "https://aip.baidubce.com/oauth/2.0/token"
        f"?grant_type=client_credentials&client_id={ASR_CONFIG['api_key']}&client_secret={ASR_CONFIG['secret_key']}"
    )
    try:
        response = requests.get(url, timeout=10)
        response.raise_for_status()
        return response.json()["access_token"]
    except Exception as e:
        print(f"âŒ è·å–Tokenå¤±è´¥ï¼š{str(e)}")
        return ""


def record_wav_16k(out_wav="recorded.wav") -> str | None:
    """å½•éŸ³å‡½æ•°ï¼ˆ16kHzå•å£°é“ï¼‰ï¼Œæ”¯æŒè®¾å¤‡å…¼å®¹ä¸é‡è¯•æœºåˆ¶"""
    vad = webrtcvad.Vad(VAD_CONFIG["mode"])  # ä½¿ç”¨æœ€æ–°VADçµæ•åº¦
    RATE, CHANNELS, WIDTH = VAD_CONFIG["sample_rate"], 1, 2
    print("ğŸ¤ å¼€å§‹å½•éŸ³ï¼ˆåœæ­¢è¯´è¯æŒ‡å®šæ—¶é—´åè‡ªåŠ¨ç»“æŸï¼‰...")

    audio_chunks = []
    silence_frame_count = 0
    max_retry = 3  # å½•éŸ³å¤±è´¥é‡è¯•æ¬¡æ•°
    retry_count = 0

    while retry_count < max_retry:
        try:
            # æ„å»ºæµå‚æ•°ï¼šæœ‰è®¾å¤‡IDåˆ™æŒ‡å®šï¼Œæ— åˆ™è‡ªåŠ¨é€‚é…
            stream_kwargs = {
                "samplerate": RATE,
                "channels": CHANNELS,
                "dtype": np.int16
            }
            if DEFAULT_MIC is not None:
                stream_kwargs["device"] = DEFAULT_MIC

            with sd.InputStream(**stream_kwargs) as stream:
                while True:
                    chunk, overflow = stream.read(VAD_FRAME_SIZE)
                    if overflow:
                        print("âš ï¸  å½•éŸ³ç¼“å†²åŒºæº¢å‡ºï¼Œéƒ¨åˆ†æ•°æ®å¯èƒ½ä¸¢å¤±")

                    chunk_bytes = chunk.tobytes()
                    is_speech = vad.is_speech(chunk_bytes, RATE)

                    if is_speech:
                        audio_chunks.append(chunk)
                        silence_frame_count = 0
                        print(f"ğŸ”Š æ£€æµ‹åˆ°è¯­éŸ³... é™éŸ³è®¡æ•°: {silence_frame_count}/{VAD_CONFIG['silence_threshold']}",
                              end="\r")
                    else:
                        if audio_chunks:
                            audio_chunks.append(chunk)
                            silence_frame_count += 1
                            silence_sec = silence_frame_count * 0.03
                            print(
                                f"ğŸŸ¡ é™éŸ³ä¸­... è®¡æ•°: {silence_frame_count}/{VAD_CONFIG['silence_threshold']}ï¼ˆ{silence_sec:.1f}ç§’ååœæ­¢ï¼‰",
                                end="\r")
                            if silence_frame_count >= VAD_CONFIG["silence_threshold"]:
                                print(f"\nğŸ›‘ æ£€æµ‹åˆ°{silence_sec:.1f}ç§’é™éŸ³ï¼Œåœæ­¢å½•éŸ³")
                                break
                        else:
                            print("ğŸŸ¡ ç­‰å¾…è¯­éŸ³è¾“å…¥...", end="\r")
            break  # å½•éŸ³æˆåŠŸï¼Œè·³å‡ºé‡è¯•å¾ªç¯
        except sd.PortAudioError as e:
            retry_count += 1
            error_msg = str(e).lower()
            if "host error" in error_msg or "mme error" in error_msg:
                print(f"\nâŒ å½•éŸ³å¤±è´¥ï¼ˆ{retry_count}/{max_retry}ï¼‰ï¼šéº¦å…‹é£è¢«å ç”¨æˆ–é©±åŠ¨é”™è¯¯")
                print("ğŸ’¡ å»ºè®®ï¼šå…³é—­å¾®ä¿¡ã€QQç­‰å ç”¨éº¦å…‹é£çš„ç¨‹åº")
            else:
                print(f"\nâŒ å½•éŸ³å¤±è´¥ï¼ˆ{retry_count}/{max_retry}ï¼‰ï¼š{str(e)}")
            if retry_count < max_retry:
                print("ğŸ”„ 1ç§’åé‡è¯•...")
                time.sleep(1)
        except Exception as e:
            print(f"\nâŒ å½•éŸ³å¼‚å¸¸ï¼š{str(e)}")
            return None

    if retry_count >= max_retry:
        print("âŒ å¤šæ¬¡é‡è¯•å¤±è´¥ï¼Œå¯èƒ½éº¦å…‹é£è¢«å ç”¨æˆ–é©±åŠ¨å¼‚å¸¸")
        return None

    if not audio_chunks:
        print("âŒ æœªæ£€æµ‹åˆ°æœ‰æ•ˆè¯­éŸ³ï¼Œå½•éŸ³å–æ¶ˆ")
        return None

    # ä¿å­˜å½•éŸ³æ–‡ä»¶
    audio_data = np.concatenate(audio_chunks, axis=0)
    with wave.open(out_wav, "wb") as wf:
        wf.setnchannels(CHANNELS)
        wf.setsampwidth(WIDTH)
        wf.setframerate(RATE)
        wf.writeframes(audio_data.tobytes())

    print(f"âœ… å½•éŸ³ä¿å­˜è‡³ï¼š{out_wav}")
    return out_wav


def play_audio_with_interrupt(file_path: str) -> None:
    """æ’­æ”¾éŸ³é¢‘ï¼Œæ”¯æŒâ€œè¾ƒå¤§å£°éŸ³ä¸­æ–­â€ï¼Œä½¿ç”¨æ‰©å¤§èŒƒå›´åçš„å‚æ•°"""
    if not os.path.exists(file_path):
        print(f"âŒ éŸ³é¢‘æ–‡ä»¶ä¸å­˜åœ¨ï¼š{file_path}")
        return

    pygame.mixer.init()
    try:
        pygame.mixer.music.load(file_path)
        print(f"ğŸ”Š å¼€å§‹æ’­æ”¾ï¼ˆæ£€æµ‹åˆ°{VAD_CONFIG['loud_sound_frames'] * 0.03:.1f}ç§’å£°éŸ³å¯ä¸­æ–­ï¼‰ï¼š{file_path}")
        pygame.mixer.music.play()

        # ä»…å½“è·å–åˆ°éº¦å…‹é£IDæ—¶ï¼Œæ‰ç›‘å¬è¾ƒå¤§å£°éŸ³ä»¥ä¸­æ–­
        if DEFAULT_MIC is not None:
            vad = webrtcvad.Vad(VAD_CONFIG["mode"])  # ä½¿ç”¨æœ€æ–°VADçµæ•åº¦
            loud_frame_count = 0  # è¿ç»­è¯­éŸ³å¸§è®¡æ•°å™¨
            try:
                stream_kwargs = {
                    "samplerate": VAD_CONFIG["sample_rate"],
                    "channels": 1,
                    "dtype": np.int16,
                    "device": DEFAULT_MIC
                }
                with sd.InputStream(**stream_kwargs) as stream:
                    while pygame.mixer.music.get_busy():
                        chunk, _ = stream.read(VAD_FRAME_SIZE)
                        is_speech = vad.is_speech(chunk.tobytes(), VAD_CONFIG["sample_rate"])

                        if is_speech:
                            loud_frame_count += 1
                            loud_sec = loud_frame_count * 0.03
                            print(
                                f"ğŸ” æ£€æµ‹åˆ°å£°éŸ³... è¿ç»­å¸§æ•°: {loud_frame_count}/{VAD_CONFIG['loud_sound_frames']}ï¼ˆ{loud_sec:.1f}ç§’ï¼‰",
                                end="\r")
                            # è¾¾åˆ°å¤§å£°éŸ³é˜ˆå€¼ï¼Œåœæ­¢æ’­æ”¾ï¼ˆä½¿ç”¨æ›´æ–°åçš„å‚æ•°ï¼‰
                            if loud_frame_count >= VAD_CONFIG["loud_sound_frames"]:
                                print(f"\nğŸ”‡ æ£€æµ‹åˆ°{loud_sec:.1f}ç§’å£°éŸ³ï¼Œåœæ­¢æ’­æ”¾")
                                pygame.mixer.music.stop()
                                break
                        else:
                            loud_frame_count = 0
                            print(f"ğŸŸ¡ æ’­æ”¾ä¸­ï¼ˆç­‰å¾…{VAD_CONFIG['loud_sound_frames'] * 0.03:.1f}ç§’å£°éŸ³ï¼‰...", end="\r")

                        time.sleep(0.01)
            except sd.PortAudioError as e:
                print(f"âš ï¸  ç›‘å¬å£°éŸ³å¤±è´¥ï¼ˆå°†ç»§ç»­æ’­æ”¾ï¼‰ï¼š{str(e)}")
                while pygame.mixer.music.get_busy():
                    time.sleep(0.1)
        else:
            # æ— éº¦å…‹é£IDæ—¶ï¼Œä»…æ™®é€šæ’­æ”¾ï¼ˆä¸æ”¯æŒä¸­æ–­ï¼‰
            print("â„¹ï¸  æœªæŒ‡å®šéº¦å…‹é£ï¼Œæ’­æ”¾æ—¶ä¸æ”¯æŒå£°éŸ³ä¸­æ–­")
            while pygame.mixer.music.get_busy():
                time.sleep(0.1)

        print("âœ… æ’­æ”¾ç»“æŸ")
    except pygame.error as e:
        print(f"âŒ æ’­æ”¾å¤±è´¥ï¼š{str(e)}")
    finally:
        pygame.mixer.quit()


# --------------------------- 4. æ ¸å¿ƒåŠŸèƒ½ ---------------------------
def speech_to_text(wav_path: str) -> str | None:
    """è¯­éŸ³è½¬æ–‡å­—ï¼ˆè°ƒç”¨ç™¾åº¦ASRï¼‰"""
    token = get_baidu_token()
    if not token:
        return None
    try:
        with open(wav_path, "rb") as f:
            audio_bytes = f.read()
    except Exception as e:
        print(f"âŒ è¯»å–éŸ³é¢‘å¤±è´¥ï¼š{str(e)}")
        return None

    payload = {
        "format": "wav", "rate": 16000, "channel": 1, "token": token,
        "cuid": "python-voice-assistant", "speech": base64.b64encode(audio_bytes).decode(),
        "len": len(audio_bytes), "dev_pid": ASR_CONFIG["dev_pid"]
    }
    try:
        response = requests.post(
            ASR_CONFIG["url"], headers={"Content-Type": "application/json"},
            json=payload, timeout=15
        )
        data = response.json()
        if data.get("err_no") == 0:
            text = data["result"][0].strip()
            print(f"âœ… ASRè¯†åˆ«ç»“æœï¼š{text}")
            return text
        print(f"âŒ ASRè¯†åˆ«å¤±è´¥ï¼š{data}")
        return None
    except Exception as e:
        print(f"âŒ ASRè¯·æ±‚å¤±è´¥ï¼š{str(e)}")
        return None


def text_to_speech(text: str, out_file: str = TTS_CONFIG["default_out"]) -> str | None:
    """æ–‡å­—è½¬è¯­éŸ³ï¼ˆè°ƒç”¨ç™¾åº¦TTSï¼Œä½¿ç”¨æœ€æ–°TTSå‚æ•°ï¼‰"""
    # è¿‡æ»¤ç‰¹æ®Šå­—ç¬¦ï¼Œé¿å…TTSæ¥å£æŠ¥é”™
    for char in ['#', '&', '@', '!', '*', ';']:
        text = text.replace(char, '')
    # é™åˆ¶å•æ¡æ–‡æœ¬é•¿åº¦ï¼ˆå…¼é¡¾é…é¢ä¸æ¥å£é™åˆ¶ï¼Œä¸Šé™å·²æ”¹ä¸º999000å­—ï¼‰
    max_len = min(120, TTS_CONFIG["daily_char_limit"] - get_daily_char_usage())
    if len(text) > max_len:
        text = text[:max_len - 3] + "..."
        print(f"âš ï¸  æ–‡æœ¬æˆªæ–­ï¼š{text}")
    if not text:
        print("âŒ æ— æœ‰æ•ˆæ–‡æœ¬")
        return None
    if not check_quota(text):
        return None

    try:
        # ä½¿ç”¨é¢æ¿è°ƒèŠ‚åçš„TTSå‚æ•°ï¼ˆéŸ³é‡ã€è¯­é€Ÿã€è¯­è°ƒã€å‘éŸ³äººï¼‰
        result = tts_client.synthesis(
            text, lang="zh", ctp=1,
            options={
                "vol": TTS_CONFIG["vol"],
                "spd": TTS_CONFIG["spd"],
                "pit": TTS_CONFIG["pit"],
                "per": TTS_CONFIG["per"]
            }
        )
        if isinstance(result, dict):
            print(f"âŒ TTSå¤±è´¥ï¼š{result.get('err_msg')}")
            if "limit reached" in result.get("err_msg", "").lower():
                print("ğŸ’¡ éœ€è´­ä¹°èµ„æºåŒ…æˆ–æ¬¡æ—¥é‡ç½®é…é¢")
            return None
        # ä¿å­˜TTSéŸ³é¢‘æ–‡ä»¶
        with open(out_file, "wb") as f:
            f.write(result)
        update_char_usage(len(text))
        print(f"âœ… TTSä¿å­˜è‡³ï¼š{out_file} | æ–‡æœ¬ï¼š{text}")
        return out_file
    except Exception as e:
        print(f"âŒ TTSè¯·æ±‚å¤±è´¥ï¼š{str(e)}")
        return None


def call_chat_api(prompt: str) -> str | None:
    """è°ƒç”¨æœ¬åœ°èŠå¤©APIï¼Œæ”¯æŒå¯¹è¯å†å²è®°å¿†å’ŒAIèƒŒæ™¯è®¾å®š"""
    global conversation_history, ai_background

    if not prompt:
        print("âŒ æ— å¯¹è¯å†…å®¹")
        return None

    # æ„å»ºæç¤ºä¿¡æ¯ï¼ŒåŒ…å«AIèƒŒæ™¯è®¾å®š
    system_prompt = ""
    if ai_background:
        system_prompt = f"ä»¥ä¸‹æ˜¯ä½ çš„èƒŒæ™¯è®¾å®šï¼Œè¯·ä¸¥æ ¼éµå®ˆï¼š{ai_background}\n\n"

    # æ„å»ºåŒ…å«å†å²è®°å½•çš„å®Œæ•´å¯¹è¯
    full_conversation = "\n".join([
        f"ç”¨æˆ·: {item['user']}\nAI: {item['ai']}"
        for item in conversation_history
    ])

    # æ‹¼æ¥ç³»ç»Ÿæç¤ºã€å†å²å¯¹è¯ä¸å½“å‰æŸ¥è¯¢
    if full_conversation:
        full_prompt = f"{system_prompt}{full_conversation}\nç”¨æˆ·: {prompt}\nAI:"
    else:
        full_prompt = f"{system_prompt}ç”¨æˆ·: {prompt}\nAI:"

    # è°ƒç”¨æœ¬åœ°Chat API
    url = "http://localhost:8000/chat/"
    data = {
        "prompt": full_prompt,
        "options": {"temperature": 0.7, "max_tokens": 200}
    }

    try:
        response = requests.post(url, json=data, timeout=20)
        response.raise_for_status()
        reply = response.json().get("response", "").strip()
        print(f"âœ… Chatå›å¤ï¼š{reply}")
        return reply
    except Exception as e:
        print(f"âŒ Chatè¯·æ±‚å¤±è´¥ï¼š{str(e)}")
        return None


def test_health_api() -> None:
    """æµ‹è¯•æœ¬åœ°APIå¥åº·çŠ¶æ€"""
    url = "http://localhost:8000/health"
    try:
        response = requests.get(url, timeout=5)
        print(f"âœ… å¥åº·æ£€æŸ¥ï¼š{response.json()}")
    except Exception as e:
        print(f"âŒ å¥åº·æ£€æŸ¥å¤±è´¥ï¼š{str(e)}")


# --------------------------- 5. ä¸šåŠ¡æµç¨‹ï¼ˆä½¿ç”¨åŠ¨æ€å”¤é†’è¯ï¼‰ ---------------------------
def wake_up_detect() -> bool:
    """å”¤é†’æ£€æµ‹ï¼šä½¿ç”¨å¯é…ç½®çš„å”¤é†’è¯"""
    global conversation_history, waiting_for_wakeup, input_mode, wake_word

    # è¿›å…¥å”¤é†’ç­‰å¾…çŠ¶æ€æ—¶ï¼Œé‡ç½®ä¸ºè¯­éŸ³è¾“å…¥å¹¶æ¸…ç©ºå†å²è®°å½•
    if waiting_for_wakeup:
        with mode_lock:
            input_mode = "voice"  # å”¤é†’æ—¶é»˜è®¤ä½¿ç”¨è¯­éŸ³è¾“å…¥
        conversation_history = []
        print("ğŸ§¹ å·²æ¸…ç©ºå†å²è®°å½•ï¼Œç­‰å¾…æ–°çš„å”¤é†’...")

    print(f"\nğŸ” ç­‰å¾…å”¤é†’è¯ï¼ˆ{wake_word}ï¼‰ï¼Œåœæ­¢è¯´è¯æŒ‡å®šæ—¶é—´åè‡ªåŠ¨å½•éŸ³ç»“æŸ...")
    wav_file = record_wav_16k(out_wav="wake_up.wav")
    if not wav_file:
        return False

    recognized_text = speech_to_text(wav_file)
    if recognized_text and wake_word in recognized_text:
        # å¦‚æœæœ‰AIèƒŒæ™¯è®¾å®šï¼Œæç¤ºç”¨æˆ·
        if ai_background:
            print(f"âœ… æ£€æµ‹åˆ°å”¤é†’è¯ï¼š{wake_word}ï¼ˆå½“å‰AIèƒŒæ™¯è®¾å®šå·²ç”Ÿæ•ˆï¼‰")
        else:
            print(f"âœ… æ£€æµ‹åˆ°å”¤é†’è¯ï¼š{wake_word}")
        waiting_for_wakeup = False
        return True

    print(f"âŒ æœªæ£€æµ‹åˆ°å”¤é†’è¯ï¼ˆè¯†åˆ«ç»“æœï¼š{recognized_text or 'æ— '}ï¼Œå”¤é†’è¯ï¼š{wake_word}ï¼‰")
    return False


def voice_interaction_flow() -> None:
    """å®Œæ•´è¯­éŸ³äº¤äº’æµç¨‹ï¼šæ”¯æŒåŠ¨æ€å”¤é†’è¯å’Œæ‰©å±•çš„ä¸­æ–­æ—¶é•¿è®¾ç½®"""
    global waiting_for_wakeup, input_mode, conversation_history, ai_background, show_control_panel, wake_word

    print("=" * 50)
    print(f"ğŸ¯ è¯­éŸ³åŠ©æ‰‹å¯åŠ¨ï¼šå½“å‰å”¤é†’è¯ä¸ºã€Œ{wake_word}ã€ï¼ˆå¯åœ¨æ§åˆ¶é¢æ¿ä¿®æ”¹ï¼‰")
    print(f"ğŸ¯ TTSæ¯æ—¥é…é¢ï¼š{TTS_CONFIG['daily_char_limit']}å­—")
    print("=" * 50)

    # è®¾ç½®æ¨¡å¼åˆ‡æ¢ç›‘å¬å™¨
    setup_mode_switch_listener()

    # æç¤ºéº¦å…‹é£é€‚é…çŠ¶æ€
    if DEFAULT_MIC is None:
        print("âš ï¸  æœªæ˜ç¡®æŒ‡å®šéº¦å…‹é£è®¾å¤‡ï¼Œå°†å°è¯•è‡ªåŠ¨é€‚é…ï¼ˆå¯èƒ½å½±å“å½•éŸ³ç¨³å®šæ€§ï¼‰")
        print("ğŸ’¡ å»ºè®®ï¼šæ£€æŸ¥éº¦å…‹é£é©±åŠ¨æˆ–å…³é—­å ç”¨éº¦å…‹é£çš„ç¨‹åº\n")

    # ä¸»å¾ªç¯ï¼šæŒç»­è¿è¡Œ
    while True:
        # 1. ç­‰å¾…å”¤é†’ï¼ˆæœªå”¤é†’æ—¶å¾ªç¯æ£€æµ‹ï¼‰
        while not wake_up_detect():
            time.sleep(0.5)

        # 2. å”¤é†’æˆåŠŸï¼šè¿›å…¥å¯¹è¯æ¨¡å¼
        print("\nğŸ‰ å”¤é†’æˆåŠŸï¼æ”¯æŒæŒ‡ä»¤ï¼š")
        print(f"   - å”¤é†’è¯ï¼šå½“å‰ä¸ºã€Œ{wake_word}ã€ï¼ˆå¯åœ¨æ§åˆ¶é¢æ¿ä¿®æ”¹ï¼‰")
        print("   - æ­£å¸¸å¯¹è¯ï¼šç›´æ¥è¯´è¯æé—®")
        print("   - æ‰“å¼€æ§åˆ¶é¢æ¿ï¼šè¯´ã€æ§åˆ¶é¢æ¿ã€‘æˆ–æŒ‰Alté”®")
        print("   - è¿”å›å”¤é†’ï¼šè¯´ã€å†è§ã€‘")
        print("   - åˆ‡æ¢è¾“å…¥æ¨¡å¼ï¼šæŒ‰Enteré”®(æ–‡å­—)/Tabé”®(è¯­éŸ³)")
        print(f"â„¹ï¸ TTSæ¯æ—¥é…é¢ï¼š{get_daily_char_usage()}/{TTS_CONFIG['daily_char_limit']}å­—")

        # æ˜¾ç¤ºå½“å‰AIèƒŒæ™¯è®¾å®šçŠ¶æ€
        if ai_background:
            print(f"â„¹ï¸ å½“å‰AIèƒŒæ™¯è®¾å®šï¼š{ai_background[:50]}{'...' if len(ai_background) > 50 else ''}")

        print("ğŸ’¡ æç¤ºï¼šå½“å‰è¾“å…¥æ¨¡å¼ - " + (
            "æ–‡å­—è¾“å…¥ï¼ˆæŒ‰Tabè¿”å›è¯­éŸ³ï¼‰" if input_mode == "text" else "è¯­éŸ³è¾“å…¥ï¼ˆæŒ‰Enteråˆ‡æ¢æ–‡å­—ï¼‰\n"))

        # 3. å¯¹è¯å¾ªç¯ï¼ˆå”¤é†’åæŒç»­äº¤äº’ï¼‰
        while not waiting_for_wakeup:
            # æ£€æŸ¥æ˜¯å¦éœ€è¦æ‰“å¼€æ§åˆ¶é¢æ¿ï¼ˆAlté”®è§¦å‘ï¼‰
            if show_control_panel:
                show_control_panel = False  # é‡ç½®æ ‡è®°
                print(f"ğŸ”§ å‡†å¤‡æ‰“å¼€æ§åˆ¶é¢æ¿...")
                # æ’­æ”¾æç¤ºéŸ³
                panel_audio = text_to_speech("æ­£åœ¨ä¸ºæ‚¨æ‰“å¼€å‚æ•°æ§åˆ¶é¢æ¿ï¼Œè¯·åœ¨çª—å£ä¸­è°ƒèŠ‚å‚æ•°ã€‚", "panel_notify.mp3")
                if panel_audio:
                    play_audio_with_interrupt(panel_audio)
                # æ‰“å¼€æ§åˆ¶é¢æ¿ï¼ˆé˜»å¡ç›´åˆ°ç”¨æˆ·å…³é—­çª—å£ï¼‰
                create_control_panel()

                # æ§åˆ¶é¢æ¿å…³é—­åï¼Œæ˜¾ç¤ºå½“å‰å”¤é†’è¯
                print(f"â„¹ï¸ å½“å‰å”¤é†’è¯å·²æ›´æ–°ä¸ºï¼šã€Œ{wake_word}ã€")

                # å¦‚æœé¢æ¿å…³é—­åå¤„äºå”¤é†’çŠ¶æ€ï¼Œè¯´æ˜å¯èƒ½æ›´æ”¹äº†èƒŒæ™¯è®¾å®šï¼Œéœ€è¦é‡æ–°å”¤é†’
                if waiting_for_wakeup:
                    # æç¤ºç”¨æˆ·éœ€è¦é‡æ–°å”¤é†’
                    wakeup_again_audio = text_to_speech(f"AIå·²é‡ç½®ï¼Œè¯·è¯´{wake_word}é‡æ–°å”¤é†’ã€‚", "wakeup_again.mp3")
                    if wakeup_again_audio:
                        play_audio_with_interrupt(wakeup_again_audio)
                    break

                # é¢æ¿å…³é—­åæç¤º
                after_panel_audio = text_to_speech("å‚æ•°é¢æ¿å·²å…³é—­ï¼Œå¯ç»§ç»­æ­£å¸¸å¯¹è¯ã€‚", "after_panel.mp3")
                if after_panel_audio:
                    play_audio_with_interrupt(after_panel_audio)
                continue

            current_mode = input_mode  # ä¿å­˜å½“å‰æ¨¡å¼ï¼Œé¿å…åœ¨å¤„ç†è¿‡ç¨‹ä¸­æ¨¡å¼è¢«åˆ‡æ¢

            # æ ¹æ®å½“å‰æ¨¡å¼è·å–ç”¨æˆ·è¾“å…¥
            if current_mode == "text":
                # æ–‡å­—è¾“å…¥æ¨¡å¼
                user_text = get_text_input("è¯·è¾“å…¥æ–‡å­—ï¼ˆæŒ‰Cancelè¿”å›è¯­éŸ³è¾“å…¥ï¼‰: ")
                if not user_text:  # ç”¨æˆ·å–æ¶ˆè¾“å…¥
                    with mode_lock:
                        input_mode = "voice"
                    print("ğŸ¤ å·²åˆ‡æ¢åˆ°è¯­éŸ³è¾“å…¥æ¨¡å¼")
                    continue
                print(f"ğŸ’¬ ç”¨æˆ·ï¼ˆæ–‡å­—è¾“å…¥ï¼‰ï¼š{user_text}")
            else:
                # è¯­éŸ³è¾“å…¥æ¨¡å¼
                user_audio = record_wav_16k("user_command.wav")
                if not user_audio:
                    continue

                user_text = speech_to_text(user_audio)
                if not user_text:
                    # æœªå¬æ¸…æ—¶æç¤ºé‡è¯•
                    retry_audio = text_to_speech("æˆ‘æ²¡å¬æ¸…ï¼Œè¯·å†è¯´ä¸€é~", "retry.mp3")
                    if retry_audio:
                        play_audio_with_interrupt(retry_audio)
                    continue

            # æŒ‡ä»¤åˆ†æ”¯åˆ¤æ–­
            # åˆ†æ”¯1ï¼šæ‰“å¼€æ§åˆ¶é¢æ¿ï¼ˆè¯­éŸ³æŒ‡ä»¤ï¼‰
            if "æ§åˆ¶é¢æ¿" in user_text:
                print(f"ğŸ”§ æ”¶åˆ°æŒ‡ä»¤ï¼š{user_text} â†’ å¯åŠ¨å‚æ•°é¢æ¿")
                # æ’­æ”¾æç¤ºéŸ³
                panel_audio = text_to_speech("æ­£åœ¨ä¸ºæ‚¨æ‰“å¼€å‚æ•°æ§åˆ¶é¢æ¿ï¼Œè¯·åœ¨çª—å£ä¸­è°ƒèŠ‚å‚æ•°ã€‚", "panel_notify.mp3")
                if panel_audio:
                    play_audio_with_interrupt(panel_audio)
                # æ‰“å¼€æ§åˆ¶é¢æ¿ï¼ˆé˜»å¡ç›´åˆ°ç”¨æˆ·å…³é—­çª—å£ï¼‰
                create_control_panel()

                # æ§åˆ¶é¢æ¿å…³é—­åï¼Œæ˜¾ç¤ºå½“å‰å”¤é†’è¯
                print(f"â„¹ï¸ å½“å‰å”¤é†’è¯å·²æ›´æ–°ä¸ºï¼šã€Œ{wake_word}ã€")

                # å¦‚æœé¢æ¿å…³é—­åå¤„äºå”¤é†’çŠ¶æ€ï¼Œè¯´æ˜å¯èƒ½æ›´æ”¹äº†èƒŒæ™¯è®¾å®šï¼Œéœ€è¦é‡æ–°å”¤é†’
                if waiting_for_wakeup:
                    # æç¤ºç”¨æˆ·éœ€è¦é‡æ–°å”¤é†’
                    wakeup_again_audio = text_to_speech(f"AIå·²é‡ç½®ï¼Œè¯·è¯´{wake_word}é‡æ–°å”¤é†’ã€‚", "wakeup_again.mp3")
                    if wakeup_again_audio:
                        play_audio_with_interrupt(wakeup_again_audio)
                    break

                # é¢æ¿å…³é—­åæç¤º
                after_panel_audio = text_to_speech("å‚æ•°é¢æ¿å·²å…³é—­ï¼Œå¯ç»§ç»­æ­£å¸¸å¯¹è¯ã€‚", "after_panel.mp3")
                if after_panel_audio:
                    play_audio_with_interrupt(after_panel_audio)
                continue

            # åˆ†æ”¯2ï¼šè¿”å›å”¤é†’çŠ¶æ€
            elif "å†è§" in user_text:
                print(f"ğŸ‘‹ æ”¶åˆ°è¿”å›æŒ‡ä»¤ï¼š{user_text}")
                exit_audio = text_to_speech(f"å·²è¿”å›å”¤é†’ç­‰å¾…çŠ¶æ€ï¼Œè¯´{wake_word}ç»§ç»­äº¤æµã€‚", "exit.mp3")
                if exit_audio:
                    play_audio_with_interrupt(exit_audio)
                waiting_for_wakeup = True
                break

            # åˆ†æ”¯3ï¼šæ­£å¸¸å¯¹è¯ï¼ˆè°ƒç”¨Chat APIï¼‰
            else:
                chat_reply = call_chat_api(user_text)
                if not chat_reply:
                    # å›å¤å¤±è´¥æ—¶æç¤º
                    no_reply_audio = text_to_speech("æŠ±æ­‰ï¼Œæš‚æ—¶æ— æ³•å›å¤ï¼Œè¯·ç¨åå†è¯•ã€‚", "no_reply.mp3")
                    if no_reply_audio:
                        play_audio_with_interrupt(no_reply_audio)
                    continue

                # ä¿å­˜å¯¹è¯å†å²ï¼ˆé™åˆ¶10è½®ï¼Œé¿å…å†…å­˜å ç”¨è¿‡é«˜ï¼‰
                conversation_history.append({
                    "user": user_text,
                    "ai": chat_reply
                })
                if len(conversation_history) > 10:
                    conversation_history = conversation_history[-10:]
                print(f"ğŸ“ å·²ä¿å­˜å¯¹è¯å†å²ï¼ˆå…±{len(conversation_history)}è½®ï¼‰")

                # æ’­æ”¾AIå›å¤ï¼ˆä½¿ç”¨æœ€æ–°TTSå‚æ•°ï¼‰
                print(f"ğŸ¤– AIï¼š{chat_reply}")
                reply_audio = text_to_speech(chat_reply, "chat_reply.mp3")
                if reply_audio:
                    play_audio_with_interrupt(reply_audio)

            # æç¤ºåç»­æ“ä½œ
            print("\n" + "-" * 30)
            print(f"ğŸ’¡ å”¤é†’è¯ï¼šã€Œ{wake_word}ã€ï¼ˆå¯åœ¨æ§åˆ¶é¢æ¿ä¿®æ”¹ï¼‰")
            print("ğŸ’¡ å¯ç»§ç»­æ“ä½œï¼šè¯´é—®é¢˜/è¯´æ§åˆ¶é¢æ¿/æŒ‰Alté”®/å†è§")
            print(f"ğŸ’¡ å½“å‰è¾“å…¥æ¨¡å¼ï¼š{input_mode}ï¼ˆæŒ‰Enteråˆ‡æ¢æ–‡å­—ï¼ŒæŒ‰Tabåˆ‡æ¢è¯­éŸ³ï¼‰")
            print(
                f"ğŸ’¡ TTSé…é¢å‰©ä½™ï¼š{TTS_CONFIG['daily_char_limit'] - get_daily_char_usage()}/{TTS_CONFIG['daily_char_limit']}å­—")
            print("-" * 30 + "\n")


# --------------------------- 6. æ‰§è¡Œå…¥å£ ---------------------------
if __name__ == "__main__":
    test_health_api()  # å¯åŠ¨æ—¶æµ‹è¯•APIå¥åº·çŠ¶æ€
    try:
        voice_interaction_flow()  # å¯åŠ¨äº¤äº’æµç¨‹
    except KeyboardInterrupt:
        print("\nğŸ”Œ ç¨‹åºè¢«æ‰‹åŠ¨ä¸­æ–­")
    finally:
        # æ¸…ç†ä¸´æ—¶éŸ³é¢‘æ–‡ä»¶
        for tmp_file in ["wake_up.wav", "user_command.wav", "chat_reply.mp3", "retry.mp3",
                         "no_reply.mp3", "exit.mp3", "panel_notify.mp3", "after_panel.mp3", "wakeup_again.mp3"]:
            if os.path.exists(tmp_file):
                os.remove(tmp_file)
        print("ğŸ—‘ï¸  ä¸´æ—¶æ–‡ä»¶å·²æ¸…ç†")